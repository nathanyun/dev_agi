import os

import gradio as gr
from dotenv import load_dotenv, find_dotenv
from langchain.schema import AIMessage, HumanMessage
from langchain_openai import ChatOpenAI

# åŠ è½½ .env åˆ°ç¯å¢ƒå˜é‡
_ = load_dotenv(find_dotenv())

# Initialize Langfuse handler
from langfuse.callback import CallbackHandler

langfuse_handler = CallbackHandler(
    secret_key=os.getenv("LANGFUSE_SECRET_KEY"),
    public_key=os.getenv("LANGFUSE_PUBLIC_KEY"),
    host="https://cloud.langfuse.com",  # ğŸ‡ªğŸ‡º EU region
    # host="https://us.cloud.langfuse.com", # ğŸ‡ºğŸ‡¸ US region
)

"""
message: ç”¨æˆ·è¾“å…¥
history: å¯¹è¯å†å²
"""

# å®šä¹‰å¯¹è¯å‡½æ•°
def chat_func(message, history):
    """langchain å¤šè½®å¯¹è¯"""
    history_langchain_format = []
    for human, ai in history:
        history_langchain_format.append(HumanMessage(content=human))
        history_langchain_format.append(AIMessage(content=ai))

    # æ·»åŠ ç”¨æˆ·è¾“å…¥åˆ°å†å²è®°å½•
    history_langchain_format.append(HumanMessage(content=message))

    llm = ChatOpenAI(temperature=1.0, model='gpt-3.5-turbo-0613')

    # Add Langfuse handler as callback (classic and LCEL)
    gpt_response = llm.invoke(history_langchain_format, config={"callbacks": [langfuse_handler]})
    return gpt_response.content


if __name__ == "__main__":
    # å¯ç”¨gradio
    gr.ChatInterface(chat_func, title='Chatbot', theme='soft').launch(share=True)
